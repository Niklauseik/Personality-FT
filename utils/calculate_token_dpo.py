import os
import json
import tiktoken

# ä¿®æ”¹ä¸ºä½ çš„ DPO æ–‡ä»¶è·¯å¾„
DPO_FILE = "datasets/mbti_dpo/ENTJ_3200.jsonl"

# é€‰æ‹© tokenizerï¼ˆgpt-4 / gpt-4o / gpt-3.5 éƒ½ç”¨ cl100k_baseï¼‰
tokenizer = tiktoken.get_encoding("cl100k_base")

def count_tokens(text: str) -> int:
    """è®¡ç®—æ–‡æœ¬ token æ•°"""
    return len(tokenizer.encode(text))

# å¼€å§‹ç»Ÿè®¡
total_tokens = 0
sample_count = 0

with open(DPO_FILE, "r", encoding="utf-8") as f:
    for line in f:
        sample = json.loads(line)
        sample_count += 1

        prompt = sample["input"]["messages"][0]["content"]
        preferred = sample["preferred_output"][0]["content"]
        non_preferred = sample["non_preferred_output"][0]["content"]

        total_tokens += count_tokens(prompt) + count_tokens(preferred) + count_tokens(non_preferred)

# è¾“å‡ºç»“æœ
print(f"âœ… æ–‡ä»¶å: {os.path.basename(DPO_FILE)}")
print(f"ğŸ“¦ æ ·æœ¬æ€»æ•°: {sample_count}")
print(f"ğŸ”¢ æ€» token æ•°: {total_tokens}")
