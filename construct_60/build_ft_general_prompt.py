import os
import json

# è®¾å®šæ•°æ®ç›®å½•
SAMPLES_DIR = "datasets/mbti_samples"
OUTPUT_DIR = "datasets/mbti_ft"

# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ç”¨æˆ·è¾“å…¥ç›®æ ‡ MBTI æ€§æ ¼
mbti_type = input("è¯·è¾“å…¥ MBTI æ€§æ ¼ç±»å‹ï¼ˆå¦‚ ENTJ, ISFP ç­‰ï¼‰ï¼š").strip().upper()

# MBTI ç»´åº¦å¯¹åº”çš„æ•°æ®é›†
MBTI_TO_DATASET = {
    "E": "en_energy_extraversion.json",
    "I": "en_energy_introversion.json",
    "S": "en_information_sensing.json",
    "N": "en_information_intuition.json",
    "T": "en_decision_thinking.json",
    "F": "en_decision_feeling.json",
    "J": "en_execution_judging.json",
    "P": "en_execution_perceiving.json",
}

# éªŒè¯è¾“å…¥
if len(mbti_type) != 4 or any(c not in MBTI_TO_DATASET for c in mbti_type):
    print("âŒ è¾“å…¥é”™è¯¯ï¼Œè¯·è¾“å…¥æœ‰æ•ˆçš„ MBTI ç±»å‹ï¼ˆå¦‚ ENTJ, INFPï¼‰")
    exit(1)

# é€‰æ‹©å¯¹åº”æ•°æ®é›†
selected_files = [MBTI_TO_DATASET[c] for c in mbti_type]
print(f"ğŸ“Œ é€‰æ‹©çš„æ•°æ®é›†: {selected_files}")

# **åˆå¹¶æ•°æ®**
combined_data = []
for file_name in selected_files:
    file_path = os.path.join(SAMPLES_DIR, file_name)
    
    if not os.path.exists(file_path):
        print(f"âš ï¸ æ–‡ä»¶ç¼ºå¤±: {file_name}ï¼Œè·³è¿‡è¯¥ç±»åˆ«")
        continue
    
    with open(file_path, "r", encoding="utf-8") as f:
        data = json.load(f)

        # **è½¬æ¢ä¸º `messages` æ ¼å¼**
        for item in data:
            # ç§»é™¤ inputï¼Œå¦‚æœä¸ºç©º
            user_content = item["instruction"]
            if item.get("input") and item["input"].strip():
                user_content += "\n" + item["input"]

            # ç»„è£… OpenAI å¾®è°ƒæ ¼å¼
            messages = [
                {"role": "system", "content": "You are an AI assistant with a strong, distinctive personality."},
                {"role": "user", "content": user_content},
                {"role": "assistant", "content": item["output"]}
            ]
            combined_data.append({"messages": messages})

# **ä¿å­˜ä¸º JSONL**
output_file = os.path.join(OUTPUT_DIR, f"{mbti_type}_general.jsonl")
with open(output_file, "w", encoding="utf-8") as f:
    for entry in combined_data:
        f.write(json.dumps(entry, ensure_ascii=False) + "\n")

print(f"âœ… è®­ç»ƒæ•°æ®é›†å·²ä¿å­˜è‡³: {output_file}ï¼Œå…± {len(combined_data)} æ¡æ•°æ®ï¼ˆJSONL æ ¼å¼ï¼‰")
