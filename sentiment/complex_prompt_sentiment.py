import openai
import pandas as pd
import os
import random
from sklearn.metrics import accuracy_score, precision_recall_fscore_support

# è¯»å– OpenAI API Key
from utils import config_manager
config_manager = config_manager.ConfigManager()
api_key = config_manager.get_api_key("openai")

# åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
client = openai.OpenAI(api_key=api_key)

# æ›¿æ¢ä¸ºæ— å¾®è°ƒçš„ GPT-4o-mini
base_model = "gpt-4o-mini"

# è¯»å–æµ‹è¯•æ•°æ®é›†
test_file = "datasets/sentiment.csv"
df = pd.read_csv(test_file)

# é¢„å®šä¹‰å››ç§ MBTI é£æ ¼
mbti_prompts = {
    "ENTJ": "You are a Commander personality type with the Extraverted, Intuitive, Thinking, and Judging traits. You are a decisive person who loves momentum and accomplishment. You gather information to construct your creative visions but rarely hesitate for long before acting on them.",
    
    "ISFP": "You are an Adventurer personality type with the Introverted, Observant, Feeling, and Prospecting traits. You tend to have an open mind, approaching life, new experiences, and people with grounded warmth. Your ability to stay in the moment helps you uncover exciting potentials.",
    
    "INTP": "You are a Logician personality type with the Introverted, Intuitive, Thinking, and Prospecting traits. You enjoy taking an unconventional approach to many aspects of life. You often seek out unlikely paths, mixing willingness to experiment with personal creativity.",
    
    "ESFJ": "You are a Consul personality type with the Extraverted, Observant, Feeling, and Judging traits. You are attentive and people-focused, and you enjoy taking part in your social community. Your achievements are guided by decisive values, and you willingly offer guidance to others."
}

# **æµ‹è¯•å­˜å‚¨ç›®å½•**
results_dir = "results/mbti_sentiment_complex"
os.makedirs(results_dir, exist_ok=True)

# éå†å››ç§ MBTI é£æ ¼
for mbti_type, system_message in mbti_prompts.items():
    print(f"ğŸ” Testing MBTI role: {mbti_type}")

    # ç»“æœå­˜å‚¨è·¯å¾„
    mbti_results_dir = os.path.join(results_dir, mbti_type)
    os.makedirs(mbti_results_dir, exist_ok=True)

    # **æŠ½å– 50 æ¡æ•°æ®**
    sample_df = df.sample(n=1173, random_state=42)

    # åˆå§‹åŒ–é¢„æµ‹åˆ—è¡¨
    predictions = []

    # éå†æµ‹è¯•æ•°æ®è¿›è¡Œé¢„æµ‹
    for i, row in sample_df.iterrows():
        query = row["query"].strip()
        true_label = row["answer"].strip()

        try:
            # å‘é€ API è¯·æ±‚
            response = client.chat.completions.create(
                model=base_model,
                messages=[
                    {"role": "system", "content": system_message},
                    {"role": "user", "content": f"{query}\nOnly reply with the sentiment label: Positive, Negative, or Neutral."}
                ]
            )

            # è§£ææ¨¡å‹é¢„æµ‹çš„æƒ…æ„Ÿç±»åˆ«
            predicted_label = response.choices[0].message.content.strip()
            predictions.append(predicted_label)

        except Exception as e:
            print(f"âŒ Prediction failed, error: {e}")
            predictions.append("error")  # å¤±è´¥æ—¶å¡«å…… "error"
    
    # **å­˜å‚¨é¢„æµ‹ç»“æœ**
    sample_df["prediction"] = predictions
    results_file = os.path.join(mbti_results_dir, "sentiment_with_predictions.csv")
    sample_df.to_csv(results_file, index=False)
    print(f"âœ… Predictions saved to: {results_file}")

    # **è®¡ç®— Metrics**
    true_labels = sample_df["answer"].str.lower()
    pred_labels = sample_df["prediction"].str.lower()

    accuracy = accuracy_score(true_labels, pred_labels)
    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, pred_labels, average="macro", zero_division=0)

    # **ä¿å­˜ Metrics ç»“æœ**
    metrics_file = os.path.join(mbti_results_dir, "metrics.txt")
    with open(metrics_file, "w") as f:
        f.write(f"Accuracy: {accuracy:.4f}\n")
        f.write(f"Precision: {precision:.4f}\n")
        f.write(f"Recall: {recall:.4f}\n")
        f.write(f"F1 Score: {f1:.4f}\n")

    print(f"âœ… Evaluation metrics saved to: {metrics_file}")
