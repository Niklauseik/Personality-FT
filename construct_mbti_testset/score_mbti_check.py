import openai
import pandas as pd
import os
import math
import time

# è¯»å– OpenAI API Key
from utils import config_manager
config_manager = config_manager.ConfigManager()
api_key = config_manager.get_api_key("openai")

# åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
client = openai.OpenAI(api_key=api_key)

# æ›¿æ¢ä¸ºä½ çš„å¾®è°ƒæ¨¡å‹ ID
fine_tuned_model = "gpt-4o-mini"

# è¯»å– MBTI é—®é¢˜æ•°æ®é›†ï¼ˆå®Œæ•´æ•°æ®ï¼‰
test_file = "datasets/mbti_questions.csv"
df = pd.read_csv(test_file)

# **æ‰‹åŠ¨è¾“å…¥ `x` å˜é‡ï¼Œå†³å®šç»“æœå­˜å‚¨è·¯å¾„**
x = input("è¯·è¾“å…¥æµ‹è¯•åç§°ï¼ˆç»“æœå°†å­˜å…¥ results/x æ–‡ä»¶å¤¹ï¼‰ï¼š ").strip()

# ç»“æœå­˜å‚¨ç›®å½•
results_dir = f"results/{x}"
os.makedirs(results_dir, exist_ok=True)

# **æ„é€  API è¯·æ±‚çš„ Prompt**
system_message = (
    "You are answering an MBTI personality test."
    "Respond to each question with a score from 0 to 6, where: \n"
    "0 = Strongly Agree\n"
    "1 = Agree\n"
    "2 = Slightly Agree\n"
    "3 = Neutral\n"
    "4 = Slightly Disagree\n"
    "5 = Disagree\n"
    "6 = Strongly Disagree\n"
    "Each answer must be on a new line and must contain only the number (0-6), nothing else."
)

# **æŒ‰æ‰¹æ¬¡è¯·æ±‚ API**
BATCH_SIZE = 20  # æ¯æ‰¹ 10 ä¸ªé—®é¢˜
MAX_RETRIES = 3  # æœ€å¤šé‡è¯• 3 æ¬¡
scores = []

num_batches = math.ceil(len(df) / BATCH_SIZE)

for i in range(num_batches):
    batch_df = df.iloc[i * BATCH_SIZE: (i + 1) * BATCH_SIZE]
    query = "\n".join([f"Q{idx+1}: {q}" for idx, q in enumerate(batch_df["Question"].tolist())])

    retry_count = 0
    success = False

    while retry_count < MAX_RETRIES and not success:
        try:
            response = client.chat.completions.create(
                model=fine_tuned_model,
                messages=[
                    {"role": "system", "content": system_message},
                    {"role": "user", "content": query}
                ]
            )

            # **æ‰“å° API å“åº”ï¼Œä¾¿äºè°ƒè¯•**
            model_response = response.choices[0].message.content.strip()
            print(f"ğŸ“Œ Batch {i+1}/{num_batches}ï¼ˆå°è¯• {retry_count + 1} æ¬¡ï¼‰åŸå§‹æ¨¡å‹å›ç­”:\n{model_response}\n")

            # **è§£ææ¨¡å‹å›ç­”**
            batch_answers = model_response.split("\n")

            # **æ£€æŸ¥è¿”å›æ ¼å¼**
            if len(batch_answers) != len(batch_df):
                raise ValueError(f"âŒ æœŸæœ› {len(batch_df)} ä¸ªç­”æ¡ˆï¼Œä½†æ”¶åˆ° {len(batch_answers)} ä¸ª: {batch_answers}")

            # **è½¬æ¢ä¸ºæ•´æ•°**
            batch_scores = []
            for ans in batch_answers:
                try:
                    score = int(ans.strip())
                    if 0 <= score <= 6:  # âœ… ä¿®æ­£ä¸º 0-6
                        batch_scores.append(score)
                    else:
                        raise ValueError(f"âŒ éæ³•å¾—åˆ†: {score}ï¼ˆåº”åœ¨ 0-6 ä¹‹é—´ï¼‰")
                except ValueError:
                    raise ValueError(f"âŒ è§£æå¤±è´¥ï¼Œéæ•´æ•°: {ans}")

            # **è§£ææˆåŠŸï¼Œå­˜å…¥ scores**
            scores.extend(batch_scores)
            success = True

        except Exception as e:
            print(f"âš ï¸ API è°ƒç”¨å¤±è´¥ï¼ˆå°è¯• {retry_count + 1}/{MAX_RETRIES}ï¼‰ï¼Œé”™è¯¯: {e}")
            retry_count += 1
            time.sleep(1)  # ç­‰å¾… 1 ç§’å†é‡è¯•

    if not success:
        print(f"âŒ Batch {i+1}/{num_batches} å¤±è´¥ï¼Œå·²é‡è¯• {MAX_RETRIES} æ¬¡ï¼Œè·³è¿‡è¯¥æ‰¹æ¬¡")
        continue  # è·³è¿‡è¿™ä¸ª batchï¼Œç»§ç»­ä¸‹ä¸€ä¸ª batch

# **å­˜å‚¨åŸå§‹è¯„åˆ†ç»“æœ**
df["Score"] = scores
results_csv_file = os.path.join(results_dir, "mbti_scores.csv")
df.to_csv(results_csv_file, index=False)

print(f"âœ… æµ‹è¯•å®Œæˆï¼Œè¯„åˆ†å·²ä¿å­˜è‡³: {results_csv_file}")
